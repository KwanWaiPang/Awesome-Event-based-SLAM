<p align="center">
  <h1 align="center">
  Awesome-Event-based-SLAM
  </h1>
</p>

This repository contains a curated list of resources addressing SLAM using *Event Camera*.

If you find some ignored papers, **feel free to [*create pull requests*](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM/blob/pdf/How-to-PR.md), or [*open issues*](https://github.com/KwanWaiPang/Awesome-Event-based-SLAM/issues/new)**. 

Contributions in any form to make this list more comprehensive are welcome.

If you find this repositorie is useful, a simple star should be the best affirmation. ðŸ˜Š
For academic used, please considering citing the following:
```bibtex
@article{GuanPhdThesis,
      title={Event-based Vision for 6-DOF Pose Tracking and 3D Mapping},
      author={Guan, Weipeng},
      journal={HKU Theses Online (HKUTO)},
      year={2025},
      publisher={The University of Hong Kong (Pokfulam, Hong Kong)}
}      
```

Feel free to share this list with others!


## Event-based Pose Estimation

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection](https://arxiv.org/pdf/2504.00139)|[![Github stars](https://img.shields.io/github/stars/smartroboticslab/SuperEvent.svg)](https://github.com/smartroboticslab/SuperEvent)|[website](https://smartroboticslab.github.io/SuperEvent/)| 
|2025|`arXiv`|[SuperEIO: Self-Supervised Event Feature Learning for Event Inertial Odometry](https://arxiv.org/pdf/2503.22963)|[![Github stars](https://img.shields.io/github/stars/arclab-hku/SuperEIO.svg)](https://github.com/arclab-hku/SuperEIO)|[website](https://arclab-hku.github.io/SuperEIO/)|
|2025|`RAL`|[Event-Frame-Inertial Odometry Using Point and Line Features Based on Coarse-to-Fine Motion Compensation](https://ieeexplore.ieee.org/abstract/document/10855459)|[![Github stars](https://img.shields.io/github/stars/choibottle/C2F-EFIO.svg)](https://github.com/choibottle/C2F-EFIO)|-|
|2024|`arXiv`|[DEIO: Deep Event Inertial Odometry](https://arxiv.org/pdf/2411.03928)|[![Github stars](https://img.shields.io/github/stars/arclab-hku/DEIO.svg)](https://github.com/arclab-hku/DEIO)|[website](https://kwanwaipang.github.io/DEIO/)|
|2024|`IROS`|[Deep Visual Odometry with Events and Frames](https://arxiv.org/pdf/2309.09947)|[![Github stars](https://img.shields.io/github/stars/uzh-rpg/rampvo.svg)](https://github.com/uzh-rpg/rampvo)|RAMP-VO| 
|2024|`arXiv`|[EROAM: Event-based Camera Rotational Odometry and Mapping in Real-time](https://arxiv.org/pdf/2411.11004)|[![Github stars](https://img.shields.io/github/stars/wlxing1901/eroam.svg)](https://github.com/wlxing1901/eroam)|-|
|2024|`3DV`|[Deep event visual odometry](https://arxiv.org/pdf/2312.09800)|[![Github stars](https://img.shields.io/github/stars/tum-vision/DEVO.svg)](https://github.com/tum-vision/DEVO)|---|
|2024|`TRO`|[CMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM System using Contrast Maximization](https://arxiv.org/pdf/2403.08119)|[![Github stars](https://img.shields.io/github/stars/tub-rip/cmax_slam.svg)](https://github.com/tub-rip/cmax_slam)|-|
|2024|`TIV`|[Dh-ptam: a deep hybrid stereo events-frames parallel tracking and mapping system](https://arxiv.org/pdf/2306.01891)|[![Github stars](https://img.shields.io/github/stars/AbanobSoliman/DH-PTAM.svg)](https://github.com/AbanobSoliman/DH-PTAM)|Superpoint+[stereo ptam](https://github.com/uoip/stereo_ptam)|
|2023|`TIV`|[MC-VEO: A visual-event odometry with accurate 6-DoF motion compensation](https://ieeexplore.ieee.org/abstract/document/10275026)|[![Github stars](https://img.shields.io/github/stars/huangfeng95/mc-veo-buildconf.svg)](https://github.com/huangfeng95/mc-veo-buildconf)|-|
|2022|`Processes`|[Contrast maximization-based feature tracking for visual odometry with an event camera](https://www.mdpi.com/2227-9717/10/10/2081)|-|-|
|2022|`Sensor`|[Visual Odometry with an Event Camera Using Continuous Ray Warping and Volumetric Contrast Maximization](https://arxiv.org/pdf/2107.03011)|-|-| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|---|`arXiv`|---|---|---| 
|2016|`ICRA`|[Fast localization and tracking using event sensors](https://merl.com/publications/docs/TR2016-033.pdf)|---|---| 
|2016|`ECCV`|[Real-time 3D reconstruction and 6-DoF tracking with an event camera](https://core.ac.uk/download/pdf/77017474.pdf)|---|---| 
|2016|`IROS`|[Low-latency visual odometry using event-based feature tracks](https://infoscience.epfl.ch/bitstreams/8b6efd05-e55b-45ad-9932-89c939c5c6d8/download)|---|---| 
|2015|`arXiv`|[Event-based camera pose tracking using a generative event model](https://arxiv.org/pdf/1510.01972)|---|---| 
|2014|`IEEE/RSJ International Conference on Intelligent Robots and Systems`|[Event-based, 6-DOF pose tracking for high-speed maneuvers](https://www.zora.uzh.ch/id/eprint/125447/1/IROS14_Mueggler.pdf)|---|---| 
|2014|`ICRA`|[Event-based 3D SLAM with a depth-augmented dynamic vision sensor](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d7e293687b47f24943ced291a01cb08b60588189)|---|---| 
|2014|`ICRA`|[Low-latency event-based visual odometry](https://infoscience.epfl.ch/record/199738/files/ICRA14_Censi.pdf)|---|---| 
|2013|`International Conference on Computer Vision Systems`|[Simultaneous localization and mapping for event-based vision systems](https://www.academia.edu/download/46707309/Simultaneous_Localization_and_Mapping_fo20160622-16469-sz3iui.pdf)|---|---| 
|2012|`IEEE International Conference on Robotics and Biomimetics`|[Event-based particle filtering for robot self-localization](https://www.academia.edu/download/46707382/Event-based_particle_filtering_for_robot20160622-4108-1dk2qxl.pdf)|---|---| 
|2008|`J. Solid State Circ`|[Simultaneous mosaicing and tracking with an event camera](https://bmva-archive.org.uk/bmvc/2014/files/abstract066.pdf)|---|---| 



<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->


## Event-based Depth Estimation

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2024|`TPAMI`|[Secrets of Event-based Optical Flow, Depth and Ego-motion Estimation by Contrast Maximization](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10517639)|[![Github stars](https://img.shields.io/github/stars/tub-rip/event_based_optical_flow.svg)](https://github.com/tub-rip/event_based_optical_flow)|-|
|2019|`CVPR`|[Unsupervised event-based learning of optical flow, depth, and egomotion](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.pdf)|-|-| 
|2018|`CVPR`|[A Unifying Contrast Maximization Framework for Event Cameras, with Applications to Motion, Depth and Optical Flow Estimation](https://openaccess.thecvf.com/content_cvpr_2018/papers/Gallego_A_Unifying_Contrast_CVPR_2018_paper.pdf)|-|[supplementary material](https://www.ifi.uzh.ch/dam/jcr:a22071c9-b284-43c6-8f71-6433627b2db2/CVPR18_Gallego.pdf)| 


<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->


## Other Resources
* [Course: Event-based Robot Vision](https://www.youtube.com/playlist?list=PL03Gm3nZjVgUFYUh3v5x8jVonjrGfcal8)
* [HKU-Dataset for Event-based VO/VIO/SLAM](https://github.com/arclab-hku/Event_based_VO-VIO-SLAM)
* Paper Survey for Event-based Contrast Maximization: [Paper list](https://github.com/KwanWaiPang/Awesome-Event-based-Contrast-Maximization) and [blog](https://kwanwaipang.github.io/Awesome-Event-based-Contrast-Maximization/)
